In this Binary classification project there are bit large no of features and less no of observations or samples, so doing effective feature selection and suitable model selection according to data type and distribution were among the most important tasks.
As actual names of features are unknown and with the help of summary statistics I got to know that the most of values in dataset are 0s then all the columns contain very large no of small float values except the last three columns i.e - X55,56 and X57, also the distributions of train and test datasets are almost same, so I was not that much concerned about the outliers.
As both the label classes are slightly imbalanced in ratio 60:40, so there is no necessity of data balancing unless one want to do data augmentation to improve model performance given the less no of samples. I used this approach with ADASYN and got good metrics with KNeighborsClassifier.
With this large no of features it was challenging to visualize Input-Output correlation and Input-Input multi-collinearity using heatmap corr() function,so I opted for bar plot which helped me during feature selection.
Both datasets are highly positive skewed with very high no of 0s, so I used Cbrt transformation instead of log or boxcox transformation to scale data. One more benefit of Cbrt transformation is that it works well even when there are some negative values in dataset.
As feature selection is most crucial process in this project, I used multiple algorithms to do effective feature selection. I used PCA screeplot, Input-Output barplot, Random Forest feature importance and LogisticRegression penalty methods thereby selecting 45 most important features.
**Model Selection Process** - I used SVM classifier because the dataset is highly sparse, also there are large no of features relative to less no of samples. SVM is non-probabilistic binary linear classifier and works best for two class classification problem, also as it is optimal margin based classification technique, less computational resources are required and support vectors are only feature vectors for deciding decision boundary. Although, the RandomForest and LogisticRegression models were also giving good evaluation metric scores with RandomForest scores approximately equal to SVM but looking at the dataset and interpretability of classifier model, I decided to go for SVM classifier.
I split training data into 80:20 ratio where 20% being validation data for model evaluation using KFold cross validation and hyper-parameter tuning. By KFold cross validation I observed that the standard deviation value is bit high i.e - 1.440%, which is a risk factor and could be reduced to least possible value doing more normalization and reducing variance in data.
I used learning curves as my final evaluation metric to check model performance with respect to the no of training sample, from both training and validation curves I observed the model is performing well till 3000 training samples without significant overfitting/underfitting.
**Dependencies/libraries &amp; their versions** - [Python -3.8.8, Pandas - 1.2.4, Numpy - 1.20.1, Jupyter -1.0.0, scipy - 1.6.2, scikit-learn - 0,24.1, matplotlib - 3.3.4, seaborn - 0.11.1 ]
